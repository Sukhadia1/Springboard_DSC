{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "\n",
    "from IPython.core.pylabtools import figsize\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting Working Directory\n",
    "os.getcwd()\n",
    "\n",
    "#Setting style and font size for graphs\n",
    "sns.set_style(\"whitegrid\")\n",
    "mpl.rcParams['font.size'] = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7377415, 70)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load original data into dataframe\n",
    "file ='train_clean.csv'\n",
    "\n",
    "#chunksize = 10 ** 6\n",
    "#for chunk in pd.read_csv(file, chunksize=chunksize):\n",
    "#    process(chunk)\n",
    "\n",
    "df = pd.read_csv(file)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('msno', axis=1, inplace = True)\n",
    "\n",
    "df['isrc_year'] = df.isrc_year.apply(lambda x: x if x != 'year_missing' else -1)\n",
    "df['isrc_year'] = df['isrc_year'].astype('int8')\n",
    "\n",
    "#Converting to categories\n",
    "cat_names = list(df.select_dtypes(include='object').columns)\n",
    "df[cat_names] = df[cat_names].astype('category')\n",
    "#df['language'] = df['language'].astype('category')\n",
    "\n",
    "int_names = list(df.select_dtypes(include='int64').columns)\n",
    "df[int_names] = df[int_names].astype('int32')\n",
    "\n",
    "int_names_8 = ['composer_artist_lyricist', 'composer_artist']\n",
    "df[int_names_8] = df[int_names_8].astype('uint8')\n",
    "\n",
    "\n",
    "float_names = list(df.select_dtypes(include='float64').columns)\n",
    "df[float_names] = df[float_names].astype('float32')\n",
    "\n",
    "float_names = list(df.select_dtypes(include='float32').columns)\n",
    "float_names.remove('song_length')\n",
    "df[float_names] = df[float_names].astype('float16')\n",
    "\n",
    "#ua = ['ua_1', 'ua_2', 'ua_3', 'ua_4', 'ua_5', 'ua_6', 'ua_7', 'ua_8', 'ua_9', 'ua_10']\n",
    "#df.drop('genre_ids_encoded', axis=1, inplace = True)\n",
    "#df.drop('artist_name_encoded', axis=1, inplace = True)\n",
    "\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7377415 entries, 0 to 7377414\n",
      "Data columns (total 69 columns):\n",
      "source_system_tab           category\n",
      "source_screen_name          category\n",
      "source_type                 category\n",
      "target                      int32\n",
      "song_length                 float32\n",
      "language                    float16\n",
      "city                        int32\n",
      "bd                          int32\n",
      "gender                      category\n",
      "registered_via              int32\n",
      "lyricist_count              int32\n",
      "artist_count                int32\n",
      "composer_count              int32\n",
      "genre_count                 int32\n",
      "isrc_year                   int8\n",
      "duration                    int32\n",
      "registration_year           int32\n",
      "registration_month          int32\n",
      "registration_day            int32\n",
      "registration_weekday        int32\n",
      "expiration_year             int32\n",
      "expiration_month            int32\n",
      "expiration_day              int32\n",
      "expiration_weekday          int32\n",
      "song_freq                   int32\n",
      "composer_artist_lyricist    uint8\n",
      "composer_artist             uint8\n",
      "count_song_played           int32\n",
      "count_artist_played         int32\n",
      "genre_ids_encoded           float16\n",
      "artist_freq                 float16\n",
      "composer_encoded            float16\n",
      "artist_name_encoded         float16\n",
      "lyricist_encoded            float16\n",
      "name_encoded                float16\n",
      "isrc_country_encoded        float16\n",
      "us_1                        float16\n",
      "us_2                        float16\n",
      "us_3                        float16\n",
      "us_4                        float16\n",
      "us_5                        float16\n",
      "us_6                        float16\n",
      "us_7                        float16\n",
      "us_8                        float16\n",
      "us_9                        float16\n",
      "us_10                       float16\n",
      "us_11                       float16\n",
      "us_12                       float16\n",
      "us_13                       float16\n",
      "us_14                       float16\n",
      "us_15                       float16\n",
      "ug_1                        float16\n",
      "ug_2                        float16\n",
      "ug_3                        float16\n",
      "ug_4                        float16\n",
      "ug_5                        float16\n",
      "ua_1                        float16\n",
      "ua_2                        float16\n",
      "ua_3                        float16\n",
      "ua_4                        float16\n",
      "ua_5                        float16\n",
      "ua_6                        float16\n",
      "ua_7                        float16\n",
      "ua_8                        float16\n",
      "ua_9                        float16\n",
      "ua_10                       float16\n",
      "usr_1                       float16\n",
      "usr_2                       float16\n",
      "usr_3                       float16\n",
      "dtypes: category(4), float16(41), float32(1), int32(20), int8(1), uint8(2)\n",
      "memory usage: 1.2 GB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating Numeric and Non_numeric Data\n",
    "numeric = df.select_dtypes(exclude = 'category')\n",
    "categorical = df.select_dtypes(include = 'category')\n",
    "\n",
    "#Creating Dummy variables for Categorical Data using One Hot Encoding\n",
    "dummies = pd.get_dummies(categorical,drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#numeric.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "#Creating our Feature and Target Data Set: X, y respectively\n",
    "\n",
    "X = pd.concat([numeric,dummies],axis=1).drop('target', axis = 1)\n",
    "y = df.target\n",
    "\n",
    "#Splitting Data into Training and Test Data Set\n",
    "X_train,X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state = 42)\n",
    "\n",
    "mean_length = X_train.song_length.mean()\n",
    "X_train.song_length.fillna(mean_length, inplace = True)\n",
    "X_test.song_length.fillna(mean_length, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3688707 entries, 1069668 to 6413414\n",
      "Columns: 106 entries, song_length to gender_male\n",
      "dtypes: float16(41), float32(1), int32(19), int8(1), uint8(44)\n",
      "memory usage: 756.3 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3391: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "X_train['language'] = X_train['language'].astype('int16')\n",
    "X_test['language'] = X_test['language'].astype('int16')\n",
    "\n",
    "int_names = list(X_train.select_dtypes(include='int32').columns)\n",
    "X_train[int_names] = X_train[int_names].astype('int16')\n",
    "X_test[int_names] = X_test[int_names].astype('int16')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3688707 entries, 1069668 to 6413414\n",
      "Columns: 106 entries, song_length to gender_male\n",
      "dtypes: float16(40), float32(1), int16(20), int8(1), uint8(44)\n",
      "memory usage: 622.7 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types of error, False Positive and False Negative. Predicting that a patient will not get readmitted but actually patient gets readmitted. This is false negative. Predicting that a patient will get readmitted but in actually he will not os called false positive. For an hospital, a false negative error is not desirable. They can still live with a false positive error. So in below models we will look at reducing false negative error. \n",
    "\n",
    "High Recall for class 'Readmitted', Better the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuring that we have the same fractions of all class in both train and test data set. Let's Calculate the fraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Line Evaluation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score, plot_roc_curve\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import plot_confusion_matrix, precision_recall_fscore_support,log_loss\n",
    "class_names = ['Not Listened', 'Listened']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_curve(y_test,y_pred_test,auc_test):\n",
    "    fpr,tpr, threshold = roc_curve(y_test, y_pred_test)\n",
    "    _ = plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.4f)' %auc_test )\n",
    "    _ = plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    _ = plt.xlim([0.0, 1.0])\n",
    "    _ = plt.ylim([0.0, 1.05])\n",
    "    _ = plt.xlabel('False Positive Rate')\n",
    "    _ = plt.ylabel('True Positive Rate')\n",
    "    _ = plt.title('Receiver operating characteristic example')\n",
    "    _ = plt.legend(loc=\"lower right\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Line Evaluation - L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Base Line Evaluation\n",
    "\n",
    "#Building the Logistic Regression Model\n",
    "lr = LogisticRegression(verbose = 2,n_jobs = 2)\n",
    "\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "#Predicting for testing and trainig data sets\n",
    "y_test_proba = lr.predict_proba(X_test)[:,1]\n",
    "y_train_proba = lr.predict_proba(X_train)[:,1]\n",
    "\n",
    "y_pred_test = lr.predict(X_test)\n",
    "y_pred_train = lr.predict(X_train)\n",
    "\n",
    "#Accuracy Score\n",
    "print(\"Training accuracy: %0.4f\" %lr.score(X_train, y_train))\n",
    "print(\"Test accuracy    : %0.4f\" %lr.score(X_test, y_test))\n",
    "#print(\"Test log loss    : %0.4f\" %log_loss(y_train, lr.predict_proba(X_train)))\n",
    "#AUC Score\n",
    "auc_train = roc_auc_score(y_train,y_train_proba)\n",
    "auc_test = roc_auc_score(y_test,y_test_proba)\n",
    "\n",
    "print('Training AUC Score: %0.4f' %auc_train)  \n",
    "print('Testing AUC Score: %0.4f' %auc_test)          \n",
    "\n",
    "print('Classification Report - Training')\n",
    "print(classification_report(y_train,y_pred_train))\n",
    "\n",
    "print('Classification Report - Testing')\n",
    "print(classification_report(y_test,y_pred_test,target_names = class_names))\n",
    "\n",
    "plot_confusion_matrix(lr, X_test, y_test,  cmap=plt.cm.Blues, normalize = 'true') #display_labels=class_names,\n",
    "plt.show()\n",
    "auc_curve(y_test,y_test_proba,auc_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X_train.isna().sum()\n",
    "y[y > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.all(np.isfinite(X_train))\n",
    "np.any(np.isnan(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coefficients = lr.coef_[0]\n",
    "coef = pd.DataFrame(coefficients, index = X_train.columns, columns = ['Coefficient'])\n",
    "coef.sort_values('Coefficient', inplace = True)\n",
    "print(\"Top 5:\")\n",
    "print(coef[-5:] )\n",
    "\n",
    "print(\"\\nBottom 5:\")\n",
    "print(coef[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Line Evaluation  - L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    }
   ],
   "source": [
    "#Building the Logistic Regression Model\n",
    "lr1 = LogisticRegression(penalty = 'l1', solver = 'liblinear', verbose = 2)\n",
    "\n",
    "lr1.fit(X_train,y_train)\n",
    "\n",
    "#Predicting for testing and trainig data sets\n",
    "y_test_proba = lr1.predict_proba(X_test)[:,1]\n",
    "y_train_proba = lr1.predict_proba(X_train)[:,1]\n",
    "\n",
    "y_pred_test = lr1.predict(X_test)\n",
    "y_pred_train = lr1.predict(X_train)\n",
    "\n",
    "#Accuracy Score\n",
    "print(\"Training accuracy: %0.4f\" %lr1.score(X_train, y_train))\n",
    "print(\"Test accuracy    : %0.4f\" %lr1.score(X_test, y_test))\n",
    "#print(\"Test log loss    : %0.4f\" %log_loss(y_train, lr.predict_proba(X_train)))\n",
    "#AUC Score\n",
    "auc_train = roc_auc_score(y_train,y_train_proba)\n",
    "auc_test = roc_auc_score(y_test,y_test_proba)\n",
    "\n",
    "print('Training AUC Score: %0.4f' %auc_train)  \n",
    "print('Testing AUC Score: %0.4f' %auc_test)          \n",
    "\n",
    "print('Classification Report - Training')\n",
    "print(classification_report(y_train,y_pred_train))\n",
    "\n",
    "print('Classification Report - Testing')\n",
    "print(classification_report(y_test,y_pred_test,target_names = class_names))\n",
    "\n",
    "plot_confusion_matrix(lr1, X_test, y_test,  cmap=plt.cm.Blues, normalize = 'true') #display_labels=class_names,\n",
    "plt.show()\n",
    "auc_curve(y_test,y_test_proba,auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bottom 5:\n",
      "                             Coefficient\n",
      "gender_male                -2.055200e-04\n",
      "duration                   -1.330714e-06\n",
      "song_length                -1.525017e-07\n",
      "source_screen_name_Payment  0.000000e+00\n",
      "count_artist_played         2.031694e-07\n",
      "song_freq                   9.266458e-05\n",
      "registration_year           1.089141e-04\n",
      "count_song_played           1.476558e-04\n",
      "isrc_year                   1.492990e-04\n",
      "expiration_year             1.584778e-04\n"
     ]
    }
   ],
   "source": [
    "coefficients1 = lr1.coef_[0]\n",
    "coef = pd.DataFrame(coefficients1, index = X_train.columns, columns = ['Coefficient'])\n",
    "coef.sort_values('Coefficient', inplace = True)\n",
    "#print(\"Zero Coefficient Features\")\n",
    "#print(coef[coef.Coefficient == 0])\n",
    "\n",
    "print(\"\\nBottom 5:\")\n",
    "print(coef[30:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figsize(12,7)\n",
    "main = np.concatenate((lr.coef_,lr1.coef_), axis =0).T\n",
    "coef = pd.DataFrame(main, index = X_train.columns, columns = ['l2','l1'])\n",
    "_ = coef.plot()\n",
    "_ = plt.xticks(rotation = 90)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post Standardization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much change in values for accuracy score for different Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing: Standardization numeric variables\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "transform_col = df.select_dtypes(exclude = 'category') \\\n",
    "                .drop(['target','composer_artist_lyricist','composer_artist'], axis = 1).columns\n",
    "\n",
    "def standardize(train,test, feature_name):\n",
    "    for col in feature_name:\n",
    "        mean = train[col].mean()\n",
    "        sd = train[col].std()\n",
    "        train[col] = (train[col] - mean)/sd\n",
    "        test[col] = (test[col] - mean)/sd\n",
    "\n",
    "    return train, test\n",
    "\n",
    "X_train_sc, X_test_sc = standardize(X_train, X_test, transform_col)\n",
    "#print(X_train[transform_col].describe())\n",
    "X_train_sc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(5,5)\n",
    "#Building the Logistic Regression Model\n",
    "lr = LogisticRegression(penalty = 'l1', solver = 'liblinear', verbose = 2)\n",
    "\n",
    "lr.fit(X_train_sc,y_train)\n",
    "\n",
    "#Predicting for testing and trainig data sets\n",
    "y_test_proba = lr.predict_proba(X_test_sc)[:,1]\n",
    "y_train_proba = lr.predict_proba(X_train_sc)[:,1]\n",
    "\n",
    "y_pred_test = lr.predict(X_test_sc)\n",
    "y_pred_train = lr.predict(X_train_sc)\n",
    "\n",
    "#Accuracy Score\n",
    "print(\"Training accuracy: %0.4f\" %lr.score(X_train_sc, y_train))\n",
    "print(\"Test accuracy    : %0.4f\" %lr.score(X_test_sc, y_test))\n",
    "#print(\"Test log loss    : %0.4f\" %log_loss(y_train, lr.predict_proba(X_train)))\n",
    "#AUC Score\n",
    "auc_train = roc_auc_score(y_train,y_train_proba)\n",
    "auc_test = roc_auc_score(y_test,y_test_proba)\n",
    "\n",
    "print('Training AUC Score: %0.4f' %auc_train)  \n",
    "print('Testing AUC Score: %0.4f' %auc_test)          \n",
    "\n",
    "print('Classification Report - Training')\n",
    "print(classification_report(y_train,y_pred_train))\n",
    "\n",
    "print('Classification Report - Testing')\n",
    "print(classification_report(y_test,y_pred_test,target_names = class_names))\n",
    "\n",
    "plot_confusion_matrix(lr, X_test_sc, y_test,  cmap=plt.cm.Blues, normalize = 'true') #display_labels=class_names,\n",
    "plt.show()\n",
    "auc_curve(y_test,y_test_proba,auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "C = [0.01,0.05, 0.1, 0.5]\n",
    "#C = np.logspace(-3,-1,10)\n",
    "#penalty = ['l1']\n",
    "model1 = ['saga', 'liblinear']\n",
    "param_grid = {'solver': model1, 'C': C}\n",
    "\n",
    "lr = LogisticRegression(penalty = 'l1')\n",
    "\n",
    "cv = GridSearchCV(lr,param_grid, cv=5, scoring = 'roc_auc', n_jobs = 2, verbose = 4)\n",
    "\n",
    "cv.fit(X_train_sc,y_train)\n",
    "\n",
    "print(cv.best_params_)\n",
    "print(cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_lr = cv.best_estimator_\n",
    "\n",
    "best_lr.fit(X_train_sc,y_train)\n",
    "\n",
    "#Predicting for testing and trainig data sets\n",
    "y_test_proba = best_lr.predict_proba(X_test_sc)[:,1]\n",
    "y_train_proba = best_lr.predict_proba(X_train_sc)[:,1]\n",
    "\n",
    "y_pred_test = best_lr.predict(X_test_sc)\n",
    "y_pred_train = best_lr.predict(X_train_sc)\n",
    "\n",
    "#Accuracy Score\n",
    "print(\"Training accuracy: %0.4f\" %best_lr.score(X_train_sc, y_train))\n",
    "print(\"Test accuracy    : %0.4f\" %best_lr.score(X_test_sc, y_test))\n",
    "#print(\"Test log loss    : %0.4f\" %log_loss(y_train, lr.predict_proba(X_train)))\n",
    "#AUC Score\n",
    "auc_train = roc_auc_score(y_train,y_train_proba)\n",
    "auc_test = roc_auc_score(y_test,y_test_proba)\n",
    "\n",
    "print('Training AUC Score: %0.4f' %auc_train)  \n",
    "print('Testing AUC Score: %0.4f' %auc_test)          \n",
    "\n",
    "print('Classification Report - Training')\n",
    "print(classification_report(y_train,y_pred_train))\n",
    "\n",
    "print('Classification Report - Testing')\n",
    "print(classification_report(y_test,y_pred_test,target_names = class_names))\n",
    "\n",
    "plot_confusion_matrix(best_lr, X_test_sc, y_test,  cmap=plt.cm.Blues, normalize = 'true') #display_labels=class_names,\n",
    "plt.show()\n",
    "auc_curve(y_test,y_test_proba,auc_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
